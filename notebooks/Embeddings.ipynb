{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ej-kIjP5d_zw"
   },
   "outputs": [],
   "source": [
    "# %pip install -U lightgbm==3.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652107969713,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "wu0YB-gRFBf7"
   },
   "outputs": [],
   "source": [
    "# %pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15068,
     "status": "ok",
     "timestamp": 1652107984776,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "IBVbPcrFEzqF",
    "outputId": "f1d39484-13a1-4e10-ee72-cd53c2894959"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from gensim) (1.16.3)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart_open>=1.8.1->gensim)\n",
      "  Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Installing collected packages: wrapt, smart_open, gensim\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gensim]2m2/3\u001b[0m [gensim]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.4.0 smart_open-7.5.0 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1652107984985,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "gboISq82XUN1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2776,
     "status": "ok",
     "timestamp": 1652107987759,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "_iSrpD4NXcSq"
   },
   "outputs": [],
   "source": [
    "from src.data import DataHelper\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652107987759,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "0zdCOhCIh7Gj"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652107987760,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "Rdt7FKjA6ovy"
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "model_dir = Path(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "data_dir = Path(\"data\")\n",
    "model_dir = Path(\"models\")\n",
    "\n",
    "TRAIN_WEEK_NUM = 4\n",
    "WEEK_NUM = TRAIN_WEEK_NUM + 2\n",
    "\n",
    "VERSION_NAME = \"Recall 1\"\n",
    "TEST = True # * Set as `False` when do local experiments to save time\n",
    "# Ensure base data dir exists, then create interim/processed subfolders\n",
    "\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "(data_dir / \"interim\" / VERSION_NAME).mkdir(parents=True, exist_ok=True)\n",
    "(data_dir / \"index_id_map\" / VERSION_NAME).mkdir(parents=True, exist_ok=True)\n",
    "(data_dir / \"external\" / VERSION_NAME).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/thangndk67/h-and-m-csv-dataset/versions/5\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"thangndk67/h-and-m-csv-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5105,
     "status": "ok",
     "timestamp": 1652107992860,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "k2v6_A2pXfTQ"
   },
   "outputs": [],
   "source": [
    "dh = DataHelper(data_dir)\n",
    "# data = dh.preprocess_data(save=True, name=\"encoded_full\") # * run only once, processed data will be saved\n",
    "data = dh.load_data(name=\"encoded_full\",load_path= path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RojtbK9GGQU"
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1652108091891,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "JZMt_s4P5mo3"
   },
   "outputs": [],
   "source": [
    "inter = data['inter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_obyQP1gia3-"
   },
   "outputs": [],
   "source": [
    "inter['t_dat'] = pd.to_datetime(inter['t_dat'])\n",
    "last_week_start = pd.to_datetime(\"2020-08-19\")\n",
    "inter = inter.loc[(inter.t_dat < last_week_start)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pZgBSutCaxn_"
   },
   "outputs": [],
   "source": [
    "feedid_seq_list = inter.groupby(['customer_id']).article_id.apply(lambda x: [str(id) for id in x] ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Qc3sLdTq5jwv"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# model_sg = Word2Vec(feedid_seq_list,  size=128, window=32, min_count=1, sg=0, sample=1e-3, negative=15, workers=32, seed=1, iter=10)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# model_sg.save(open(model_dir/'articleid_model_cbow.model','wb'))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model_sg = \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeedid_seq_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m model_sg.save(\u001b[38;5;28mopen\u001b[39m(model_dir/\u001b[33m'\u001b[39m\u001b[33marticleid_model_skipgram.model\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/gensim/models/word2vec.py:430\u001b[39m, in \u001b[36mWord2Vec.__init__\u001b[39m\u001b[34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[39m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_corpus_sanity(corpus_iterable=corpus_iterable, corpus_file=corpus_file, passes=(epochs + \u001b[32m1\u001b[39m))\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_vocab(corpus_iterable=corpus_iterable, corpus_file=corpus_file, trim_rule=trim_rule)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorpus_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorpus_total_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mend_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/gensim/models/word2vec.py:1073\u001b[39m, in \u001b[36mWord2Vec.train\u001b[39m\u001b[34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     callback.on_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqueue_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = \u001b[38;5;28mself\u001b[39m._train_epoch_corpusfile(\n\u001b[32m   1079\u001b[39m         corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words,\n\u001b[32m   1080\u001b[39m         callbacks=callbacks, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/gensim/models/word2vec.py:1434\u001b[39m, in \u001b[36mWord2Vec._train_epoch\u001b[39m\u001b[34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[39m\n\u001b[32m   1431\u001b[39m     thread.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[32m   1432\u001b[39m     thread.start()\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m trained_word_count, raw_word_count, job_tally = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_epoch_progress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreport_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_corpus_file_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/gensim/models/word2vec.py:1289\u001b[39m, in \u001b[36mWord2Vec._log_epoch_progress\u001b[39m\u001b[34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[39m\n\u001b[32m   1286\u001b[39m unfinished_worker_count = \u001b[38;5;28mself\u001b[39m.workers\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1289\u001b[39m     report = \u001b[43mprogress_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[32m   1290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[32m   1291\u001b[39m         unfinished_worker_count -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# model_sg = Word2Vec(feedid_seq_list,  size=128, window=32, min_count=1, sg=0, sample=1e-3, negative=15, workers=32, seed=1, iter=10)\n",
    "# model_sg.save(open(model_dir/'articleid_model_cbow.model','wb'))\n",
    "model_sg = Word2Vec(feedid_seq_list,  vector_size=128, window=32, min_count=1, sg=1, sample=1e-3, negative=15, workers=32, seed=1)\n",
    "model_sg.save(open(model_dir/'articleid_model_skipgram.model','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXaLEP_ClQqT"
   },
   "outputs": [],
   "source": [
    "# model_sg = pickle.load(open(model_dir/'articleid_model_cbow.model','rb'))\n",
    "model_sg = pickle.load(open(model_dir/'articleid_model_skipgram.model','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282627,
     "status": "ok",
     "timestamp": 1651987851408,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "VKXtLXe6iVxU",
    "outputId": "bdd13fb1-cf54-4638-fa84-adab37d36f9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1334713/1334713 [04:02<00:00, 5512.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# * Customer Embedding\n",
    "feedid_seq_list = inter.groupby(['customer_id']).article_id.apply(lambda x: [str(id) for id in x] ).reset_index()\n",
    "\n",
    "full_users = data['user']['customer_id'].values\n",
    "customer_embedding = np.ones((len(full_users)+1, 128))/128\n",
    "\n",
    "for uid, items in tqdm(feedid_seq_list.values):\n",
    "    if len(items)>1:\n",
    "        vec = np.mean(list(map(lambda x: model_sg[x], items)), axis=0)\n",
    "    else:\n",
    "        vec = model_sg[items[0]]\n",
    "    customer_embedding[uid] = vec/np.sqrt(np.sum(vec**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1651987853397,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "7doE4ofzkaSF",
    "outputId": "8e5635f3-2daa-4ba1-e4cc-db8984cefc83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del full_users, feedid_seq_list, inter\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiX3b0mjjb6C"
   },
   "outputs": [],
   "source": [
    "# customer_embedding.dump(data_dir/'external'/'w2v_user_embd.npy')\n",
    "customer_embedding.dump(data_dir/'external'/'w2v_skipgram_user_embd.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3477,
     "status": "ok",
     "timestamp": 1651987889348,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "MKmO5MdAoWfB",
    "outputId": "3d42c3bf-ae21-4000-e50f-39ca600b2453"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105542/105542 [00:03<00:00, 34165.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# * Article Embedding\n",
    "full_items = data['item']['article_id'].values\n",
    "article_embedding = np.ones((len(full_items)+1, 128))/128\n",
    "for item in tqdm(full_items):\n",
    "    try:\n",
    "        vec = model_sg[str(item)]\n",
    "    except:\n",
    "        vec = article_embedding[item]\n",
    "    article_embedding[item,:] = vec/np.sqrt(np.sum(vec**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqT8Y0TFpjA1"
   },
   "outputs": [],
   "source": [
    "# article_embedding.dump(data_dir/'external'/'w2v_item_embd.npy')\n",
    "article_embedding.dump(data_dir/'external'/'w2v_skipgram_item_embd.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S28-nZGic9Li"
   },
   "outputs": [],
   "source": [
    "# * Product_code Embedding\n",
    "full_products = list(data['item']['product_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8632,
     "status": "ok",
     "timestamp": 1651987900947,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "Jqp1N3o3zyXp",
    "outputId": "014ed5ba-3751-40d9-cd19-0d1e06adc7b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47224/47224 [00:07<00:00, 5918.84it/s]\n"
     ]
    }
   ],
   "source": [
    "product_embd_dict = {}\n",
    "for pid, items in tqdm(data['item'].groupby('product_code')):\n",
    "    embd = article_embedding[items['article_id'].values]\n",
    "    embd = np.sum(embd, axis=0)\n",
    "    product_embd_dict[pid] = embd/np.sqrt(np.sum(embd**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1651987900948,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "KA7xfm-ae2rH",
    "outputId": "9caa3eee-441b-45db-8a87-830f2772a005"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47224/47224 [00:00<00:00, 667652.54it/s]\n"
     ]
    }
   ],
   "source": [
    "product_embedding = np.ones((len(full_products)+1, 128))/128\n",
    "for pid,embd in tqdm(product_embd_dict.items()):\n",
    "    product_embedding[pid,:] = embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUcYAExYfL2v"
   },
   "outputs": [],
   "source": [
    "# product_embedding.dump(data_dir/'external'/'w2v_product_embd.npy')\n",
    "product_embedding.dump(data_dir/'external'/'w2v_skipgram_product_embd.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeSXuUB7T1b5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0MT5lbIUlCD"
   },
   "outputs": [],
   "source": [
    "# * Product_code Embedding\n",
    "full_products = list(data['item']['product_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2345,
     "status": "ok",
     "timestamp": 1652108084455,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "TPFbi7o-T2Dx"
   },
   "outputs": [],
   "source": [
    "dssm_item_embd = np.load(data_dir/'external'/'dssm_item_embd.npy', allow_pickle=True)\n",
    "\n",
    "product_embd_dict = {}\n",
    "for pid, items in tqdm(data['item'].groupby('product_code')):\n",
    "    embd = dssm_item_embd[items['article_id'].values-1]\n",
    "    embd = np.sum(embd, axis=0)\n",
    "    product_embd_dict[pid] = embd/np.sqrt(np.sum(embd**2))\n",
    "\n",
    "product_embedding = np.ones((len(full_products), 128))/128\n",
    "for pid,embd in tqdm(product_embd_dict.items()):\n",
    "    product_embedding[pid-1,:] = embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652108100501,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "6NRoj0fGULpv"
   },
   "outputs": [],
   "source": [
    "product_embedding.dump(data_dir/'external'/'dssm_product_embd.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9093,
     "status": "ok",
     "timestamp": 1652108237989,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "6HzzPLzTUQCL",
    "outputId": "5baffabe-580b-4860-9b5e-a219df2dcf8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47224/47224 [00:05<00:00, 8468.67it/s]\n",
      "100%|██████████| 47224/47224 [00:00<00:00, 859955.42it/s]\n"
     ]
    }
   ],
   "source": [
    "yt_item_embd = np.load(data_dir/'external'/'yt_item_embd.npy', allow_pickle=True)\n",
    "\n",
    "product_embd_dict = {}\n",
    "for pid, items in tqdm(data['item'].groupby('product_code')):\n",
    "    embd = yt_item_embd[items['article_id'].values-1]\n",
    "    embd = np.sum(embd, axis=0)\n",
    "    product_embd_dict[pid] = embd/np.sqrt(np.sum(embd**2))\n",
    "\n",
    "product_embedding = np.ones((len(full_products), 128))/128\n",
    "for pid,embd in tqdm(product_embd_dict.items()):\n",
    "    product_embedding[pid-1,:] = embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 679,
     "status": "ok",
     "timestamp": 1652108240082,
     "user": {
      "displayName": "WP Zhang",
      "userId": "08181056311681578219"
     },
     "user_tz": 240
    },
    "id": "UScGXMhLUaf-"
   },
   "outputs": [],
   "source": [
    "product_embedding.dump(data_dir/'external'/'yt_product_embd.npy')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
